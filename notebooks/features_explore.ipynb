{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7509fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPipeline prático (Etapa 1): comparar timbre entre 5 instrumentos\\n\\n\\nObjetivo: validar na prática a ideia de que timbre diferencia sons com mesma nota, duração e intensidade.\\n\\n\\nComo usar:\\n1) Preencha os caminhos dos 4 áudios (≈5s cada) nas variáveis abaixo (guitarra, piano, flauta, bateria).\\n- Idealmente: faixas monofônicas com a mesma nota (ex.: A4 = 440 Hz), volume semelhante e sem efeitos.\\n- Caso não sejam iguais, o script normaliza o nível (RMS matching) e recorta/ajusta duração.\\n2) Execute o script inteiro. Ele irá:\\n- Carregar e padronizar os áudios (mono, 22050 Hz, duração comum).\\n- Visualizar waveform, envelope e espectrograma de cada instrumento.\\n- Extrair um conjunto de features (tempo, espectrais, perceptuais) e montar um DataFrame\\ncom médias/descritores por arquivo.\\n- Plotar comparações chave (ex.: centroid, bandwidth, flux, flatness, ZCR, HNR aproximado) e\\nsalvar um CSV com as métricas agregadas.\\n\\n\\nDependências:\\n- librosa, numpy, pandas, matplotlib, scipy\\n\\n\\nObservação:\\n- Métricas como \"ataque\" e \"HNR\" aqui são aproximações simples para a etapa 1.\\nPodemos sofisticar depois (ex.: detecção de onsets/ADSR, HNR via cepstrum, etc.).\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pipeline prático (Etapa 1): comparar timbre entre 5 instrumentos\n",
    "\n",
    "\n",
    "Objetivo: validar na prática a ideia de que timbre diferencia sons com mesma nota, duração e intensidade.\n",
    "\n",
    "\n",
    "Como usar:\n",
    "1) Preencha os caminhos dos 4 áudios (≈5s cada) nas variáveis abaixo (guitarra, piano, flauta, bateria).\n",
    "- Idealmente: faixas monofônicas com a mesma nota (ex.: A4 = 440 Hz), volume semelhante e sem efeitos.\n",
    "- Caso não sejam iguais, o script normaliza o nível (RMS matching) e recorta/ajusta duração.\n",
    "2) Execute o script inteiro. Ele irá:\n",
    "- Carregar e padronizar os áudios (mono, 22050 Hz, duração comum).\n",
    "- Visualizar waveform, envelope e espectrograma de cada instrumento.\n",
    "- Extrair um conjunto de features (tempo, espectrais, perceptuais) e montar um DataFrame\n",
    "com médias/descritores por arquivo.\n",
    "- Plotar comparações chave (ex.: centroid, bandwidth, flux, flatness, ZCR, HNR aproximado) e\n",
    "salvar um CSV com as métricas agregadas.\n",
    "\n",
    "\n",
    "Dependências:\n",
    "- librosa, numpy, pandas, matplotlib, scipy\n",
    "\n",
    "\n",
    "Observação:\n",
    "- Métricas como \"ataque\" e \"HNR\" aqui são aproximações simples para a etapa 1.\n",
    "Podemos sofisticar depois (ex.: detecção de onsets/ADSR, HNR via cepstrum, etc.).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fbbd8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import hilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447b5c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 22050 # target sample rate\n",
    "TARGET_DUR = 5.0 # target duration in seconds\n",
    "ROLL_PERCENT = 0.85 # roll-off\n",
    "N_MFCC = 13\n",
    "\n",
    "\n",
    "# >>>> Substitua pelos caminhos dos seus áudios <<<<\n",
    "AUDIO_PATHS = {\n",
    "\"piano\": \"../data/piano.wav\",\n",
    "\"flute\": \"../data/flute.wav\",\n",
    "\"trumpet\": \"../data/trumpet.wav\",\n",
    "\"drums\": \"../data/drums.wav\",\n",
    "\"bass\": \"../data/bass.wav\",\n",
    "}\n",
    "\n",
    "\n",
    "OUT_DIR = Path(\"../output\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8feb260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pad_mono(path: str, sr: int = SR, target_dur: float = TARGET_DUR):\n",
    "    y, _sr = librosa.load(path, sr=sr, mono=True)\n",
    "    # pad/truncate to target_dur\n",
    "    target_n = int(target_dur * sr)\n",
    "    if len(y) < target_n:\n",
    "        y = np.pad(y, (0, target_n - len(y)))\n",
    "    else:\n",
    "        y = y[:target_n]\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2) + 1e-12)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def match_rms(y, ref_level: float = None):\n",
    "    \"\"\"Normaliza o nível RMS. Se ref_level None, usa -20 dBFS como alvo aproximado.\"\"\"\n",
    "    if ref_level is None:\n",
    "        ref_level = 10 ** (-20/20) # -20 dBFS\n",
    "    y_rms = rms(y)\n",
    "    if y_rms < 1e-9:\n",
    "        return y\n",
    "    gain = ref_level / y_rms\n",
    "    return np.clip(y * gain, -1.0, 1.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def temporal_envelope(y):\n",
    "# Envelope pelo sinal analítico (Hilbert)\n",
    "    analytic = hilbert(y)\n",
    "    env = np.abs(analytic)\n",
    "    return librosa.util.normalize(env)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def estimate_attack_time(env, sr=SR, floor_db=-60, thresh_db=-3):\n",
    "    \"\"\"Aproximação: tempo até o envelope atingir (max + thresh_db).\n",
    "    floor_db evita valores muito baixos; resultado em segundos.\"\"\"\n",
    "    env_db = librosa.amplitude_to_db(env + 1e-9, ref=np.max)\n",
    "    # ponto onde cruza -3 dB do pico\n",
    "    idx = np.argmax(env_db >= thresh_db)\n",
    "    return idx / sr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def spectral_features(y, sr=SR):\n",
    "    S = np.abs(librosa.stft(y, n_fft=2048, hop_length=512))\n",
    "    S_power = S**2\n",
    "    spec_centroid = librosa.feature.spectral_centroid(S=S, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(S=S, sr=sr)\n",
    "    spec_roll = librosa.feature.spectral_rolloff(S=S, sr=sr, roll_percent=ROLL_PERCENT)\n",
    "    spec_flat = librosa.feature.spectral_flatness(S=S)\n",
    "    spec_contrast = librosa.feature.spectral_contrast(S=S, sr=sr)\n",
    "    spec_flux = librosa.onset.onset_strength(S=librosa.power_to_db(S_power, ref=np.max))\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    return {\n",
    "    \"centroid\": spec_centroid,\n",
    "    \"bandwidth\": spec_bw,\n",
    "    \"rolloff\": spec_roll,\n",
    "    \"flatness\": spec_flat,\n",
    "    \"contrast\": spec_contrast,\n",
    "    \"flux\": spec_flux[None, :], # forma (1, T) para uniformizar\n",
    "    \"zcr\": zcr,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def perceptual_features(y, sr=SR, n_mfcc=N_MFCC):\n",
    "    S = np.abs(librosa.stft(y, n_fft=2048, hop_length=512))\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=64)\n",
    "    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel, ref=np.max), sr=sr, n_mfcc=n_mfcc)\n",
    "    chroma = librosa.feature.chroma_stft(S=S, sr=sr)\n",
    "    # tempo (aprox) e taxa de onsets\n",
    "    tempo, beats = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "    onset_rate = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr)\n",
    "    return {\n",
    "    \"mfcc\": mfcc,\n",
    "    \"chroma\": chroma,\n",
    "    \"tempo\": np.array([[tempo]]),\n",
    "    \"onset_rate\": np.array([[len(onset_rate) / (len(y)/sr + 1e-9)]]),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def summarize_feature(name, mat):\n",
    "    \"\"\"Gera estatísticas simples por feature (média, desvio, mediana).\n",
    "    mat esperado shape (F, T) ou (1, T).\"\"\"\n",
    "    mat = np.atleast_2d(mat)\n",
    "    feats = {}\n",
    "    feats[f\"{name}_mean\"] = float(np.mean(mat))\n",
    "    feats[f\"{name}_std\"] = float(np.std(mat))\n",
    "    feats[f\"{name}_median\"] = float(np.median(mat))\n",
    "    return feats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def summarize_vector(name, vec):\n",
    "    vec = np.asarray(vec).ravel()\n",
    "    return {\n",
    "        f\"{name}_mean\": float(np.mean(vec)),\n",
    "        f\"{name}_std\": float(np.std(vec)),\n",
    "        f\"{name}_median\": float(np.median(vec)),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hnr_proxy(y, sr=SR):\n",
    "    \"\"\"Proxy grosseiro para Harmonic-to-Noise Ratio usando autocorrelação.\n",
    "    Retorna valor em dB (quanto maior, mais harmônico).\"\"\"\n",
    "    y = y - np.mean(y)\n",
    "    if np.max(np.abs(y)) > 0:\n",
    "        y = y / np.max(np.abs(y))\n",
    "    ac = librosa.autocorrelate(y)\n",
    "    ac = ac / (np.max(ac) + 1e-9)\n",
    "    # pular lag 0; pegar pico maior em [2ms, 20ms] ~ [1100Hz, 50Hz]\n",
    "    minlag = int(sr/500) # 2 ms\n",
    "    maxlag = int(sr/50) # 20 ms\n",
    "    peak = np.max(ac[minlag:maxlag]) if maxlag > minlag else 0\n",
    "    noise = np.mean(ac[maxlag:]) if len(ac) > maxlag else 1e-9\n",
    "    hnr = 10*np.log10((peak+1e-9)/(noise+1e-9))\n",
    "    return hnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05b99368",
   "metadata": {},
   "outputs": [],
   "source": [
    "waves = {}\n",
    "for inst, path in AUDIO_PATHS.items():\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        print(f\"[AVISO] Arquivo não encontrado: {p}. Pule ou ajuste o caminho.\")\n",
    "        continue\n",
    "    y = load_pad_mono(str(p))\n",
    "    y = match_rms(y)\n",
    "    waves[inst] = y\n",
    "\n",
    "\n",
    "# Visualizações por instrumento\n",
    "for inst, y in waves.items():\n",
    "    t = np.arange(len(y))/SR\n",
    "    env = temporal_envelope(y)\n",
    "\n",
    "\n",
    "    # Waveform + envelope\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.title(f\"Waveform + Envelope — {inst}\")\n",
    "    plt.plot(t, y, linewidth=0.8)\n",
    "    plt.plot(t, env * np.max(np.abs(y)), linewidth=1.0)\n",
    "    plt.xlabel(\"Tempo (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / f\"{inst}_wave_env.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # Espectrograma (mel)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=SR, n_mels=96)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.title(f\"Mel-Spectrogram — {inst}\")\n",
    "    librosa.display.specshow(mel_db, sr=SR, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / f\"{inst}_melspec.png\", dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77fc7edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75408/3239046703.py:132: RuntimeWarning: invalid value encountered in log10\n",
      "  hnr = 10*np.log10((peak+1e-9)/(noise+1e-9))\n",
      "/tmp/ipykernel_75408/1761943204.py:40: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  feats[\"tempo_est_bpm\"] = float(pf[\"tempo\"][0,0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV salvo em: outputs_features_etapa1/features_resumo.csv\n",
      "CSV salvo em: outputs_features_etapa1/features_resumo.csv\n",
      "CSV salvo em: outputs_features_etapa1/features_resumo.csv\n",
      "CSV salvo em: outputs_features_etapa1/features_resumo.csv\n",
      "CSV salvo em: outputs_features_etapa1/features_resumo.csv\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for inst, y in waves.items():\n",
    "    env = temporal_envelope(y)\n",
    "    attack_s = estimate_attack_time(env, sr=SR)\n",
    "\n",
    "\n",
    "    sf = spectral_features(y)\n",
    "    pf = perceptual_features(y)\n",
    "    proxy_hnr = hnr_proxy(y)\n",
    "\n",
    "\n",
    "    feats = {\"instrumento\": inst,\n",
    "        \"rms\": rms(y),\n",
    "        \"attack_time_s\": attack_s,\n",
    "        \"hnr_proxy_db\": proxy_hnr}\n",
    "\n",
    "\n",
    "    # Resumos simples\n",
    "    for k in [\"centroid\", \"bandwidth\", \"rolloff\", \"flatness\", \"flux\", \"zcr\"]:\n",
    "        feats.update(summarize_feature(k, sf[k]))\n",
    "    feats.update(summarize_feature(\"contrast\", sf[\"contrast\"]))\n",
    "\n",
    "\n",
    "    # MFCC: média/variância por coeficiente + médias globais\n",
    "    mfcc = pf[\"mfcc\"] # (n_mfcc, T)\n",
    "    for i in range(mfcc.shape[0]):\n",
    "        feats[f\"mfcc{i+1}_mean\"] = float(np.mean(mfcc[i]))\n",
    "        feats[f\"mfcc{i+1}_std\"] = float(np.std(mfcc[i]))\n",
    "    feats[\"mfcc_global_mean\"] = float(np.mean(mfcc))\n",
    "    feats[\"mfcc_global_std\"] = float(np.std(mfcc))\n",
    "\n",
    "\n",
    "    # Chroma: média por classe de pitch\n",
    "    chroma = pf[\"chroma\"] # (12, T)\n",
    "    for i in range(12):\n",
    "        feats[f\"chroma{i}_mean\"] = float(np.mean(chroma[i]))\n",
    "\n",
    "\n",
    "    # Ritmo\n",
    "    feats[\"tempo_est_bpm\"] = float(pf[\"tempo\"][0,0])\n",
    "    feats[\"onset_rate_s\"] = float(pf[\"onset_rate\"][0,0])\n",
    "\n",
    "\n",
    "    rows.append(feats)\n",
    "\n",
    "\n",
    "    feat_df = pd.DataFrame(rows).set_index(\"instrumento\")\n",
    "    feat_df.to_csv(OUT_DIR / \"features_resumo.csv\", index=True)\n",
    "    print(f\"CSV salvo em: {OUT_DIR / 'features_resumo.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ec998c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluído. Verifique a pasta outputs_features_etapa1 com imagens e CSV.\n"
     ]
    }
   ],
   "source": [
    "metrics_to_plot = [\n",
    "    (\"centroid_mean\", \"Centroid (média)\"),\n",
    "    (\"bandwidth_mean\", \"Bandwidth (média)\"),\n",
    "    (\"rolloff_mean\", f\"Roll-off {int(ROLL_PERCENT*100)}% (média)\"),\n",
    "    (\"flatness_mean\", \"Flatness (média)\"),\n",
    "    (\"flux_mean\", \"Spectral Flux (média)\"),\n",
    "    (\"zcr_mean\", \"Zero-Crossing Rate (média)\"),\n",
    "    (\"hnr_proxy_db\", \"HNR Proxy (dB)\"),\n",
    "    (\"attack_time_s\", \"Tempo de ataque (s)\"),\n",
    "]\n",
    "\n",
    "\n",
    "for key, label in metrics_to_plot:\n",
    "    if key not in feat_df.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    feat_df[key].plot(kind=\"bar\")\n",
    "    plt.title(label)\n",
    "    plt.ylabel(label)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / f\"compare_{key}.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "print(\"Concluído. Verifique a pasta outputs_features_etapa1 com imagens e CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea506e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timbre_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
